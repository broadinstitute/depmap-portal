# Three Steps:
# 1. Generate a daintree input config file for each model and screen
# 2. Run the model fitting
# 3. Combine the output config files

rule process_model_config:
    inputs:
        # Model config yaml file
        model_config=fileref("model-config.yaml"),

        # Target matrices
        crispr_gene_effect={"type": "target_matrix", "label": "crispr_gene_effect"},
        rnai={"type": "target_matrix", "label": "rnai"},
        oncref={"type": "target_matrix", "label": "oncref"},

        # Features
        lineage={"type": "feature", "label": "lineage"},
        crispr_confounder={"type": "feature", "label": "crispr_confounder"},
        rnai_confounder={"type": "feature", "label": "rnai_confounder"},
        oncref_confounder={"type": "feature", "label": "oncref_confounder"},
        driver_events={"type": "feature", "label": "driver_events"},
        armlevel_cna={"type": "feature", "label": "armlevel_cna"},
        cytoband_cn={"type": "feature", "label": "cytoband_cn"},
        genetic_signature={"type": "feature", "label": "genetic_signature"},
        mutations_hotspot={"type": "feature", "label": "mutations_hotspot"},
        mutations_damaging={"type": "feature", "label": "mutations_damaging"},
        gene_cn={"type": "feature", "label": "gene_cn"},
        loh={"type": "feature", "label": "loh"},
        rnaseq={"type": "feature", "label": "rnaseq"},

        # Script to generate daintree input config file
        script=fileref("scripts/generate_daintree_input_configs.py"),

    run "python" with """
    import json

    config_dict = {{inputs}}
    with open("daintree_input_config.json", 'w') as f:
        json.dump(config_dict, f, indent=2)   

    """
    run "python {{ inputs.script.filename }} --model_config {{ inputs.model_config.filename }} --input_config 'daintree_input_config.json'"


rule run_fit_models:
    resources: {'slots': "0.05"} # let up to 20 of these run in parallel
    inputs:
        daintree_input_config={
          "type": "daintree_input_config"
          },
        release_taiga_id={
          "type": "release_taiga_id"
          },
        sparkles_config=fileref("sparkles-config", copy_to="sparkles-config")
    outputs:
        {
          "type": "daintree_output_config",
          "name": "{{ inputs.daintree_input_config.label }}",
          "filename": {"$filename": "daintree_output_config.json"}
        }
    run "python" with """
      import subprocess
      import os
      import glob
      import json

      input_config_filepath = "{{ inputs.daintree_input_config.filename }}"
      input_config_filename = "{{ inputs.daintree_input_config.label }}.json"

      docker_command = [
        "docker", "run",
        "--rm",
        "-v", f"{input_config_filepath}:/daintree/{input_config_filename}",
        "-v", f"{os.getcwd()}/output_data:/daintree/output_data",
        "-v", f"{os.getcwd()}/sparkles-config:/daintree/sparkles-config",
        "us.gcr.io/broad-achilles/daintree:v5",
        "collect-and-fit",
        "--input-config", input_config_filename,
        "--sparkles-config", "/daintree/sparkles-config",
        "--out", "/daintree/output_data",
        "--test", "True",
        "--upload-to-taiga", "{{ inputs.release_taiga_id.dataset_id }}",
      ]

      subprocess.run(
          docker_command,
          check=True
      )
      
      # Find the output config file using glob
      output_config_files = glob.glob(os.path.join(os.getcwd(), "output_data", "output_config_files", "*.json"))
      if not output_config_files:
          raise FileNotFoundError("No output config files found")
      
      # Use the first, there should only be one matching file
      output_config_file = output_config_files[0]
      
      try:
          with open(output_config_file, 'r') as f:
              output_config = json.load(f)
          with open("daintree_output_config.json", 'w') as f:
              json.dump(output_config, f, indent=2)
      except json.JSONDecodeError as e:
          logger.error(f"Invalid JSON in output config: {e}")
          raise
    """


rule combine_output_configs:
    inputs:
        daintree_output_config = all{
          "type": "daintree_output_config"
          }
    outputs:
        {
          "type": "combined_daintree_output_config",
          "filename": {"$filename": "combined_daintree_output_config.json"}
        }
    run "python" with """
        import json
        import os

        def merge_json_files(json_files):
            combined = {}
            
            for file_path in json_files:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                    
                model_name = list(data.keys())[0]
                screen_name = data[model_name]["input"]["screen_name"]
                
                # Initialize the screen in combined if it doesn't exist
                if screen_name not in combined:
                    combined[screen_name] = {}
                    
                # Add the model data to the appropriate screen
                combined[screen_name][model_name] = data[model_name]
            
            return combined        

        artifacts = {{ inputs.daintree_output_config }}
        list_of_files = [artifact['filename'] for artifact in artifacts]

        combined_output_config = merge_json_files(list_of_files)

        try:
            with open("combined_daintree_output_config.json", 'w') as f:
                json.dump(combined_output_config, f, indent=2)
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in combined output config: {e}")
            raise
    """
