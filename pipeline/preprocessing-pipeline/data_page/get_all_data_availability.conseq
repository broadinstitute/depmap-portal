# due to a bug in conseq's handling of `all` which can prevent a rule from being run if 
# the query returns zero results, work around this by instead matching the artifacts with a single
# input variable. We know at least _one_ value will be in that collection, so the bug
# won't manifest. Then, use the type field on each artifact to map it to the name the script is expecting
rule get_all_data_availability:
    inputs:
        artifacts=all {"type" ~ "release_taiga_id|depmap_oncref_taiga_id|rna_merged_version_taiga_id|rnai_drive_taiga_id|repurposing_matrix_taiga_id|ctd2-drug-taiga-id|gdsc_drug_taiga_id|raw-rppa-matrix|proteomics-raw|sanger_methylation_taiga_id|biomarker-correctly-transposed|ccle_mirna_taiga_id|ataq_seq_taiga_id|olink_taiga_id|sanger-proteomics|depmap_paralogs_taiga_id|depmap_long_reads_dataset"},
        rnai_broad_only={"type": "raw-dep-matrix", "label": "RNAi_Ach"},
        crispr_screen_sequence_map={"type": "crispr-screen-sequence-map"},
        script=fileref("get_all_data_availability.py"),
    outputs:
        {"type": "all-data-avail", "filename": { "$filename": "all-data-avail.csv"} }
    run "python3" with """
        import json
    
        all_artifacts = {{ inputs.artifacts }}
        regular_artifacts = [d for d in all_artifacts if d.get("type") != "depmap_long_reads_dataset"]
        depmap_long_reads_artifacts = [d for d in all_artifacts if d.get("type") == "depmap_long_reads_dataset"]

        # transformed will be our newly constructed dict of name -> artifact
        transformed = {
            # handle the ones that couldn't uniquely be identified by type specially
            "rnai_broad_only": [{{ inputs.rnai_broad_only }}],
            "crispr_screen_sequence_map": [ {{ inputs.crispr_screen_sequence_map }} ],
        }

        if depmap_long_reads_artifacts:
            transformed["depmap_long_reads_datasets"] = depmap_long_reads_artifacts

        by_type = { artifact['type'] : artifact for artifact in regular_artifacts }
        assert len(by_type) == len(regular_artifacts), "Some type was duplicated?"

        # now unpack those inputs into ids the script was using
        for dest_name, type_name in [
                ('release_taiga_id','release_taiga_id'), 
                ('oncref_taiga_id', 'depmap_oncref_taiga_id'), 
                ('rnai_merged_version_taiga_id', 'rna_merged_version_taiga_id'), 
                ('rnai_drive_taiga_id', 'rnai_drive_taiga_id'), 
                ('repurposing_matrix_taiga_id', 'repurposing_matrix_taiga_id'), 
                ('ctd2_drug_taiga_id', 'ctd2-drug-taiga-id'), 
                ('gdsc_drug_taiga_id', 'gdsc_drug_taiga_id'), 
                ('rppa_taiga_id', 'raw-rppa-matrix'), 
                ('ms_ccle_taiga_id', 'proteomics-raw'), 
                ('sanger_methylation_taiga_id', 'sanger_methylation_taiga_id'), 
                ('methylation_ccle_taiga_id', 'biomarker-correctly-transposed'), 
                ('ccle_mirna_taiga_id', 'ccle_mirna_taiga_id'), 
                ('ataq_seq_taiga_id', 'ataq_seq_taiga_id'), 
                ('olink_taiga_id', 'olink_taiga_id'), 
                ('sanger_proteomics_taiga_id', 'sanger-proteomics'), 
                ('depmap_paralogs_taiga_id', 'depmap_paralogs_taiga_id')
            ]:
            artifact = by_type.get(type_name)
            transformed[dest_name] = [ artifact ] if artifact is not None else []

        with open("inputs.json", "wt") as fd:
            fd.write(json.dumps(transformed, indent=2))
    """
    run """ python {{ inputs.script.filename }} inputs.json all-data-avail.csv """
